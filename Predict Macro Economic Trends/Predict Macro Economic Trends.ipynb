{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source(\"http://bioconductor.org/biocLite.R\")\n",
    "biocLite(\"rhdf5\")\n",
    "library(rhdf5)\n",
    "\n",
    "# Show the structure (ls)\n",
    "h5ls(\"/Users/pradmishra/Downloads/train.h5\")\n",
    "\n",
    "# Reading file\n",
    "data <- h5read(\"/Users/pradmishra/Downloads/train.h5\",\"train\")\n",
    "data_column_names <- data[[5]]\n",
    "data_column_names <- unlist(data_column_names)\n",
    "\n",
    "data_matrix <- data[[6]]\n",
    "data_matrix <- t(data_matrix)\n",
    "\n",
    "colnames(data_matrix) <- data_column_names\n",
    "\n",
    "library(data.table)\n",
    "train <- data.table(data_matrix)\n",
    "\n",
    "train\n",
    "\n",
    "sessionInfo()\n",
    "\n",
    "###############Data Analysis###########\n",
    "sum(is.na(train$derived_0))/nrow(train)*100\n",
    "mid<-round(sapply(train,function(x)sum(is.na(x)))/nrow(train)*100,1)\n",
    "sort(mid)\n",
    "# if the missing % is < 15% then we are going to impute the values, we will remove the \n",
    "# column from the model dataset\n",
    "\n",
    "# Approach 1\n",
    "# remove the features with more than 15% data missing\n",
    "# prepare a new train dataset\n",
    "library(dplyr)\n",
    "df_train1<-select(train,-fundamental_40,-fundamental_27,-fundamental_15,-fundamental_29,-fundamental_30,\n",
    "           -fundamental_43,-fundamental_13,-fundamental_14,-fundamental_16,\n",
    "           -fundamental_37,-fundamental_44,-fundamental_46,-fundamental_50,\n",
    "           -fundamental_60,-fundamental_23,-fundamental_2,-fundamental_11,\n",
    "           -fundamental_55,-fundamental_56,-fundamental_8,-fundamental_63,\n",
    "           -fundamental_39,-fundamental_54,-derived_2,-derived_4,-fundamental_35,\n",
    "           -fundamental_34,-fundamental_47,-fundamental_51,-fundamental_3, \n",
    "           -fundamental_31,-fundamental_22,-fundamental_49,-fundamental_9,\n",
    "           -fundamental_24,-fundamental_26,-fundamental_57,-fundamental_28,\n",
    "           -fundamental_61,-fundamental_1,-fundamental_6,-fundamental_38,-fundamental_5)\n",
    "library(mice)\n",
    "df_train1.1 = mice(df_train1, meth ='sample', seed =111)\n",
    "mean(df_train1$derived_0,na.rm = T)\n",
    "\n",
    "df2<-as.data.frame(apply(df_train1,2,function(x){mean(x,na.rm = T)}))\n",
    "\n",
    "plot(density(df_train1$derived_0,na.rm = T))\n",
    "\n",
    "# Approach 2\n",
    "# remove the rows with missing values and create another cleaned dataset\n",
    "df_train2<-na.omit(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(xgboost)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(as.matrix(train[,1:108]),label=train[,109])\n",
    "dtest = xgb.DMatrix(as.matrix(train[,1:108]))\n",
    "SEED=set.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'SEED' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'SEED' not found\n"
     ]
    }
   ],
   "source": [
    "#set xgb parameters\n",
    "xgb_params = list(seed=SEED,\n",
    "                 colsample=0.9,\n",
    "                 subsample=0.7,\n",
    "                 eta=0.03,\n",
    "                 #alpha=0.1,\n",
    "                 #gamma=0,\n",
    "                 objective='reg:linear',\n",
    "                 max_depth=20,\n",
    "                 min_child_weight=2,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = xgb.cv(xgb_params,\n",
    "            dtrain,\n",
    "            nrounds=100,\n",
    "            nfold=4,\n",
    "            eavl_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source(\"http://bioconductor.org/biocLite.R\")\n",
    "biocLite(\"rhdf5\")\n",
    "library(rhdf5)\n",
    "\n",
    "# Show the structure (ls)\n",
    "h5ls(\"/Users/pradmishra/Downloads/train.h5\")\n",
    "\n",
    "# Reading file\n",
    "data <- h5read(\"/Users/pradmishra/Downloads/train.h5\",\"train\")\n",
    "data_column_names <- data[[5]]\n",
    "data_column_names <- unlist(data_column_names)\n",
    "\n",
    "data_matrix <- data[[6]]\n",
    "data_matrix <- t(data_matrix)\n",
    "\n",
    "colnames(data_matrix) <- data_column_names\n",
    "\n",
    "library(data.table)\n",
    "train <- data.table(data_matrix)\n",
    "\n",
    "train\n",
    "\n",
    "sessionInfo()\n",
    "\n",
    "###############Data Analysis###########\n",
    "sum(is.na(train$derived_0))/nrow(train)*100\n",
    "mid<-round(sapply(train,function(x)sum(is.na(x)))/nrow(train)*100,1)\n",
    "sort(mid)\n",
    "# if the missing % is < 15% then we are going to impute the values, we will remove the \n",
    "# column from the model dataset\n",
    "\n",
    "# Approach 1\n",
    "# remove the features with more than 15% data missing\n",
    "# prepare a new train dataset\n",
    "library(dplyr)\n",
    "df_train1<-select(train,-fundamental_40,-fundamental_27,-fundamental_15,-fundamental_29,-fundamental_30,\n",
    "           -fundamental_43,-fundamental_13,-fundamental_14,-fundamental_16,\n",
    "           -fundamental_37,-fundamental_44,-fundamental_46,-fundamental_50,\n",
    "           -fundamental_60,-fundamental_23,-fundamental_2,-fundamental_11,\n",
    "           -fundamental_55,-fundamental_56,-fundamental_8,-fundamental_63,\n",
    "           -fundamental_39,-fundamental_54,-derived_2,-derived_4,-fundamental_35,\n",
    "           -fundamental_34,-fundamental_47,-fundamental_51,-fundamental_3, \n",
    "           -fundamental_31,-fundamental_22,-fundamental_49,-fundamental_9,\n",
    "           -fundamental_24,-fundamental_26,-fundamental_57,-fundamental_28,\n",
    "           -fundamental_61,-fundamental_1,-fundamental_6,-fundamental_38,-fundamental_5)\n",
    "library(mice)\n",
    "df_train1.1 = mice(df_train1, meth ='sample', seed =111)\n",
    "mean(df_train1$derived_0,na.rm = T)\n",
    "\n",
    "df2<-as.data.frame(apply(df_train1,2,function(x){mean(x,na.rm = T)}))\n",
    "\n",
    "plot(density(df_train1$derived_0,na.rm = T))\n",
    "\n",
    "# Approach 2\n",
    "# remove the rows with missing values and create another cleaned dataset\n",
    "df_train2<-na.omit(train)\n",
    "\n",
    "# we will go ahead with approach 2 for now, same can be applied on approach 1 \n",
    "####\n",
    "\n",
    "# split the dataset into train and test\n",
    "sample_size <- floor(0.80*nrow(df_train2))\n",
    "\n",
    "set.seed(123)\n",
    "train_ind <- sample(seq_len(nrow(df_train2)),size = sample_size)\n",
    "\n",
    "train = df_train2[train_ind,]\n",
    "test = df_train2[-train_ind,]\n",
    "\n",
    "# since the y variable is continuous we should take regression as a method\n",
    "# for predcition\n",
    "\n",
    "names(train)\n",
    "\n",
    "# Linear regression\n",
    "\n",
    "# assumptions: in order to produce good accuracy your regression model\n",
    "# should follow the assumptions listed below\n",
    "\n",
    "#1- the residuals should follow a normal distribution\n",
    "#2- no multicollineaerity in the predictors\n",
    "#3- no heteroscedasticity\n",
    "#4- linearity\n",
    "#5- no autocorrelation\n",
    "\n",
    "# model\n",
    "fit1<- lm(train$y~.,data=train)\n",
    "summary(fit1)\n",
    "fit1.1<-step(fit1,direction = \"both\")\n",
    "\n",
    "# robust regression is ruled out\n",
    "library(MASS)\n",
    "fit2<-rlm(train$y~.,data=train)\n",
    "summary(fit2)\n",
    "\n",
    "#Ridge regression (regularized regression method)\n",
    "# variable subsample for testing purpose only (offline apply it on all obs)\n",
    "subsample <- train[sample(1:nrow(train),20000,replace=F),]\n",
    "\n",
    "library(caret)\n",
    "library(glmnet)\n",
    "library(elasticnet)\n",
    "\n",
    "train_control<-trainControl(method='repeatedcv',\n",
    "                            number=4,\n",
    "                            repeats=4,\n",
    "                            verboseIter=F)\n",
    "\n",
    "lambda <- seq(from=1,to=0,by=-0.001)\n",
    "\n",
    "ridge_model <- train(x=subsample[,1:108],y=subsample$y,\n",
    "                     method='glmnet',\n",
    "                     metric='Rsquared',\n",
    "                     maximize=T,\n",
    "                     trControl=train_control,\n",
    "                     tuneGrid=expand.grid(alpha=0,\n",
    "                                          lambda=lambda))\n",
    "\n",
    "#accuracy\n",
    "mean(ridge_model$resample$Rsquared)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
